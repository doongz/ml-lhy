# Machine Learning

## Introduction

- æ‰€å±å¤§å­¦ï¼šåœ‹ç«‹å°ç£å¤§å­¸
- æˆè¯¾è€å¸ˆï¼šæå®æ¯…
- å…ˆä¿®è¦æ±‚ï¼šç†Ÿç»ƒæŒæ¡ Python
- ç¼–ç¨‹è¯­è¨€ï¼šPython
- è¯¾ç¨‹éš¾åº¦ï¼šğŸŒŸğŸŒŸğŸŒŸğŸŒŸ
- é¢„è®¡å­¦æ—¶ï¼š80 å°æ—¶
- å­¦å¹´ï¼šSpring 2022

æå®æ¯…è€å¸ˆæ˜¯å›½ç«‹å°æ¹¾å¤§å­¦çš„æ•™æˆï¼Œå…¶é£è¶£å¹½é»˜çš„æˆè¯¾é£æ ¼æ·±å—å¤§å®¶å–œçˆ±ï¼Œå¹¶ä¸”å°¤å…¶å–œæ¬¢åœ¨ PPT ä¸­æ’å…¥å®å¯æ¢¦ç­‰åŠ¨æ¼«å…ƒç´ ï¼Œæ˜¯ä¸ªéå¸¸å¯çˆ±çš„è€å¸ˆã€‚

è¿™é—¨è¯¾æŒ‚ç€æœºå™¨å­¦ä¹ çš„ç‰Œå­ï¼Œä½†å…¶è¯¾ç¨‹å†…å®¹ä¹‹å¹¿å®åœ¨ä»¤äººå’‹èˆŒï¼Œå…¶ä½œä¸šä¸€å…±åŒ…å« 15 ä¸ª labï¼Œåˆ†åˆ«æ˜¯ Regressionã€Classificationã€CNNã€Self-Attentionã€Transformerã€GANã€BERTã€Anomaly Detectionã€Explainable AIã€Attackã€Adaptationã€ RLã€Compressionã€Life-Long Learning ä»¥åŠ Meta Learningã€‚å¯è°“æ˜¯åŒ…ç½—ä¸‡è±¡ï¼Œèƒ½è®©å­¦ç”Ÿå¯¹äºæ·±åº¦å­¦ä¹ çš„ç»å¤§å¤šæ•°é¢†åŸŸéƒ½æœ‰ä¸€å®šäº†è§£ï¼Œä»è€Œå¯ä»¥è¿›ä¸€æ­¥é€‰æ‹©æƒ³è¦æ·±å…¥çš„æ–¹å‘è¿›è¡Œå­¦ä¹ ã€‚

å¤§å®¶ä¹Ÿå¤§å¯ä¸å¿…æ‹…å¿ƒä½œä¸šçš„éš¾åº¦ï¼Œå› ä¸ºæ‰€æœ‰ä½œä¸šéƒ½ä¼šæä¾›åŠ©æ•™çš„ç¤ºä¾‹ä»£ç ï¼Œå¸®ä½ å®Œæˆæ•°æ®å¤„ç†ã€æ¨¡å‹æ­å»ºç­‰ï¼Œä½ åªéœ€è¦åœ¨å…¶åŸºç¡€ä¸Šè¿›è¡Œé€‚é‡çš„ä¿®æ”¹å³å¯ã€‚è¿™ä¹Ÿæ˜¯ä¸€ä¸ªå­¦ä¹ åˆ«äººä¼˜è´¨ä»£ç çš„æå¥½æœºä¼šï¼Œå¤§å®¶éœ€è¦æ°´è¯¾ç¨‹å¤§ä½œä¸šçš„è¯ï¼Œè¿™é‡Œä¹Ÿæ˜¯ä¸€ä¸ªä¸é”™çš„èµ„æ–™æ¥æºã€‚

## Resources

- è¯¾ç¨‹ç½‘ç«™ï¼šhttps://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php
- è¯¾ç¨‹è§†é¢‘ï¼šhttps://www.youtube.com/playlist?list=PLJV_el3uVTsPM2mM-OQzJXziCGJa8nJL8
- è¯¾ç¨‹ä½œä¸šï¼š15 ä¸ª labï¼Œå‡ ä¹è¦†ç›–äº†ä¸»æµæ·±åº¦å­¦ä¹ çš„æ‰€æœ‰é¢†åŸŸï¼Œå‚è§è¯¾ç¨‹ç½‘ç«™
- å‚è€ƒä¹¦ç±ï¼šã€ŠDive into Deep Learningã€‹https://d2l.ai/

## Notes

### Lecture 1: Introduction of Deep Learning

ä»‹ç»äº†äº›æœ¬é—¨è¯¾å¯ä»¥å­¦åˆ°çš„ä¸œè¥¿

### Lecture 2: What to do if my network fails to train

ä¸ºä»€ä¹ˆå‚æ•°è¶Šå¤šï¼Œè¶Šå®¹æ˜“ overfit

è®­ç»ƒé›†ä¸å¥½

<img src="./images/image-20230108182217458.png" alt="image-20230108182217458" style="zoom:50%;" />

<img src="./images/image-20230108183339463.png" alt="image-20230108183339463" style="zoom:50%;" />

<img src="./images/image-20230108183422655.png" alt="image-20230108183422655" style="zoom:50%;" />

<img src="./images/image-20230108215257508.png" alt="image-20230108215257508" style="zoom:50%;" />

### Lecture 3: Image as input

cnn

<img src="./images/image-20230205125441972.png" alt="image-20230205125441972" style="zoom:50%;" />

<img src="./images/image-20230205131700429.png" alt="image-20230205131700429" style="zoom:50%;" />

<img src="./images/image-20230205132102613.png" alt="image-20230205132102613" style="zoom:50%;" />

<img src="./images/image-20230205132131344.png" alt="image-20230205132131344" style="zoom:50%;" />

æ·±åº¦å­¦ä¹ å¥½åœ¨å“ª

ReLU è¿›è¡Œå åŠ  + å¸¸æ•°å¯ä»£è¡¨ä»»ä½•æ–¹ç¨‹

<img src="./images/image-20230108223304383.png" alt="image-20230108223304383" style="zoom:50%;" />

<img src="./images/image-20230108223414917.png" alt="image-20230108223414917" style="zoom:50%;" />

<img src="./images/image-20230108230226158.png" alt="image-20230108230226158" style="zoom:50%;" />

<img src="./images/image-20230108232105650.png" alt="image-20230108232105650" style="zoom:50%;" />

### Lecture 4: Sequence as input

<img src="./images/image-20230205135807348.png" alt="image-20230205135807348" style="zoom:50%;" />

<img src="./images/image-20230205142626232.png" alt="image-20230205142626232" style="zoom:50%;" />

step-1 ä» a_i å¾—åˆ° q k v çš„çŸ©é˜µ

<img src="./images/image-20230205143344853.png" alt="image-20230205143344853" style="zoom:50%;" />

step-2 K å’Œ Q çš„çŸ©é˜µä¹˜ å¾—åˆ° A çŸ©é˜µ

<img src="./images/image-20230205143822509.png" alt="image-20230205143822509" style="zoom:50%;" />

step-3 V å’Œ A çš„çŸ©é˜µä¹˜å¾—åˆ° O çŸ©é˜µ

<img src="./images/image-20230205144116182.png" alt="image-20230205144116182" style="zoom:50%;" />

å¹¶å‘èƒ½åŠ›ç”±ç¡¬ä»¶æä¾›ï¼Œæ•´ä¸ªè¿‡ç¨‹éœ€è¦è®­ç»ƒçš„æ˜¯ q k v çš„ weight çŸ©é˜µ

<img src="./images/image-20230205144211354.png" alt="image-20230205144211354" style="zoom:50%;" />

<img src="./images/image-20230205151409655.png " alt="image-20230205151409655" style="zoom:50%;" />

<img src="./images/image-20230205151633597.png" alt="image-20230205151633597" style="zoom:50%;" />

self-attention vs CNN

- CNN æ˜¯ self-attention çš„ç‰¹ä¾‹ï¼ŒCNN çš„ receptive field æ˜¯å›ºå®šçš„ï¼Œself-attention çš„ receptive field æ˜¯å¯å˜çš„ï¼Œç”šè‡³æ˜¯å…¨å›¾ï¼Œç”šè‡³æ˜¯å¯ä»¥è®­ç»ƒçš„
- è®­ç»ƒé›†å°çš„æ—¶å€™ CNN æ•ˆæœå¥½äº›ï¼Œåœ¨å¤§è®­ç»ƒé›†ä¸Š self-attention æ•ˆæœæ›´å¥½

<img src="./images/image-20230205152152888.png" alt="image-20230205152152888" style="zoom:50%;" />

self-attention vs RNN

- RNN ä¸­çš„è¾“å…¥æ˜¯æœ‰è·ç¦»çš„ï¼ˆç¬¬ä¸€ä¸ªè¾“å…¥åœ¨æœ€åé¢çš„è®¡ç®—æ—¶æ…¢æ…¢ä¼šè¢«é—å¿˜ï¼‰ï¼Œself-attention ä¸­æ‰€æœ‰çš„è¾“å…¥éƒ½æ˜¯å¹³ç­‰çš„
- RNN åªèƒ½ä¸€ä¸ªä¸€ä¸ªå»ç®—ï¼Œself-attention å¯ä»¥å¹¶è¡Œè®¡ç®—

### Lecture 5: Sequence to sequence

<img src="./images/image-20230115143207868.png" alt="image-20230115143207868" style="zoom: 33%;" />

<img src="./images/image-20230115143556724.png" alt="image-20230115143556724" style="zoom:33%;" />

### Lecture 6: Generation

### Recent Advance of Self-supervised learning for NLP

### Lecture 7: Self-supervised learning for Speech and Image

### Lecture 8: Auto-encoder/ Anomaly Detection

### Lecture 9: Explainable AI

### Lecture 10: Attack

### Lecture 11: Adaptation

### Lecture 12: Reinforcement Learning

### Lecture 13: Network Compression

### Lecture 14: Life-long Learning

### Lecture 15: Meta Learning
